<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>KCT framework</title><link>https://kulvait.github.io/KCT_doc/</link><description>KCT framework documentation</description><atom:link type="application/rss+xml" href="https://kulvait.github.io/KCT_doc/rss.xml" rel="self"></atom:link><language>en</language><copyright>Contents © 2021 &lt;a href="mailto:kulvait at gmail dot com"&gt;Vojtěch Kulvait&lt;/a&gt; 
&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"&gt;&lt;img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/a&gt;&lt;span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"&gt;KCT framework wiki and blog&lt;/span&gt; by &lt;span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName"&gt;Vojtěch Kulvait&lt;/span&gt; is licensed under a &lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"&gt;Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License&lt;/a&gt;. &lt;br/&gt;
KCT framework itself is licensed under the terms of GNU GPL3 license. &lt;br/&gt;
Any data provided on this site or within the KCT framework may be subject to different licensing arrangements.
</copyright><lastBuildDate>Tue, 14 Sep 2021 16:59:10 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Working with KCT CBCT 2 Projective geometry and camera matrices to describe CT geometry</title><link>https://kulvait.github.io/KCT_doc/posts/working-with-kct-cbct-2-projective-geometry-and-camera-matrices-to-describe-ct-geometry.html</link><dc:creator>Vojtěch Kulvait</dc:creator><description>&lt;div&gt;&lt;p&gt;Before we define particular geometry corresponding to the flat panel detector CT trajectory, we need to know some theory about projective geometry and camera matrices. This will be the content of this post.&lt;/p&gt;
&lt;h3&gt;CT projections geometry&lt;/h3&gt;
&lt;p&gt;In the computer tomography, we project 3D object in $ \mathbb{R}^3 $ to the projector grid. Let's say it is a two dimensional grid that consist of rectangular pixels. Coordinates on the detector can be naturally described as the vectors in $ \mathbb{R}^2 $ since the projections are 2D images. The process of the X-ray projection is analogous to the pinhole camera model that projects the 3D scene onto the 2D plane. And therefore projective geometry is a good tool to study this correspondence.&lt;/p&gt;
&lt;h3&gt;Projective geometry&lt;/h3&gt;
&lt;p&gt;Projective space is a structure on top of an Vector space $\mathbf{V}$ that is not a vector space itself. For an introduction into the projective geometry, see &lt;a href="http://math.unife.it/insegnamenti/geometria-differenziale/materiale-didattico/projective.pdf"&gt;class notes of Nigel Hitchin&lt;/a&gt;. I will follow some of its definitions&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The projective space $\mathcal{P}(\mathbf{V})$ of a vector space $\mathbf{V}$ is a set of one dimensional subspaces of $\mathbf{V}$. The dimension of $\mathcal{P}(\mathbf{V})$ is $dim(\mathbf{V}) - 1$. Projective space of dimension $1$ is called projective line and projective space of dimension $2$ is called projective plane.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It is interesting to see in this definitions, that when we take the space $\mathbb{R}^3$, where the source is placed in its origin. We constract "a set of one dimensional subspaces of $\mathbb{R}^3$", which are all the lines through the origin representing all the rays going from the source. The number of lines with this characteristic is (almost) the same as the number of the points on the unit half sphere and I use this property, for derivation of the Cutting voxel projector. Here we first observe what uniquelly defines the flat detector CT (FDCT) setup and which properties can be described using projection matrices. &lt;/p&gt;
&lt;h3&gt;FDCT projection setup&lt;/h3&gt;
&lt;p&gt;Let's have the following FDCT setup&lt;/p&gt;
&lt;p&gt;&lt;img src="https://kulvait.github.io/KCT_doc/images/FDCTProjectionGeometry.png"&gt;&lt;/p&gt;
&lt;p&gt;There are world coordinates described by vectors $\mathbb{x} = (x_1, x_2, x_3)$. There is a source at the position $\mathbb{S} = (s_1, s_2, s_3)$. And there is a Flat panel detector which is described by the point $\chi^{(0,0)}$, where is the point $(0,0)$ at the detector and by two orthogonal vectors $\chi^1$ and $\chi^2$. Let's say that spacing of the detector pixels is determined by the length of the vectors $\chi^1$ and $\chi^2$ so that the size of the pixels is $|\chi^1| \times |\chi^2|$. Let's also say that pixel boundaries have zero thickness and where one pixel ends, another starts. We have to specify how many pixels is there in the directions $\chi^1$ and  $\chi^2$ and we have complete FDCT setup.&lt;/p&gt;
&lt;p&gt;By convention described also in previous post, the $x_3$ axis parallel with the axis of the rotation and $x_2$ axis goes from the top (above scanned subject) to bottom (under scanned object).&lt;/p&gt;
&lt;p&gt;Let's mention there is one special ray from the source, which is perpendicular to the detector. We usually call this ray principal ray and the point, where this ray hits the detector principal point. In some applications it might be convenient to shift the principal ray outside the center of the detector, see for example work on &lt;a href="https://doi.org/10.1109/TMI.2004.826950"&gt;quarter detector offset shifting to improve resolution&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;Common FDCT setup simplifications&lt;/h4&gt;
&lt;p&gt;The setup described is too general for many projectors implemented in KCT package. The only exception is &lt;a href="https://doi.org/10.1118/1.595715"&gt;Siddon projector&lt;/a&gt;, which can be used with the geometries of this generality.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://doi.org/10.1109/TMI.2010.2050898"&gt;TR and TT projectors&lt;/a&gt; by design and CVP projector by current implementation use the following simplification of the geometry. They expect, that the vector $\mathbb{\chi^2}$ is always parallel to $\mathbb{x_3}$ cartesian vector. That implies then that the normal to the detector, which can be obtained e.g. as a normalized cross product $\mathbb{\chi^1} \times \mathbb{\chi^2}$ is orthogonal to $\mathbb{x_3}$. &lt;/p&gt;
&lt;p&gt;This exclude trajectories, where the device rotates along axis not parallel with $\mathbb{x_3}$.&lt;/p&gt;
&lt;h4&gt;Camera matrix to describe FDCT setup&lt;/h4&gt;
&lt;p&gt;By the camera matrix we describe the mapping from the point $\mathbb{x} = (x_1, x_2, x_3)$ to the point on the detector given by $\mathbb{P}=(p^1, p^2)$. The point $\mathbb{x}$ will be projected onto the point $\chi^{(0,0)} + p^1 * \chi^1 + p^2 * \chi^2$. Interestingly, we don't need to know precise values of vectors $\chi^{(0,0)}, \chi^1, \chi^2$ as when we place the vector $\chi^{(0,0)}$ anywhere on the ray from the source to that vector, and scale accordingly also the vectors $\chi^1$ and $\chi^2$, we obtain obtain the same mapping between $\mathbb{x} = (x_1, x_2, x_3)$ and $\mathbb{P}=(P^1, P^2)$. In the normal detector we can not change size of the pixels, so this is just a theoretical consideration. However this has an implication that when having camera matrix in the sense of beeing a linear mapping between projective space of dimension 3 and projective space of dimension 2, we can not tell how far from the source the detector is or how far the pixels are spaced from each other. When to the camera metrix adding information of one pixel dimension or distance from projector to source, system is fully defined. &lt;/p&gt;
&lt;p&gt;Why talking about abstract projective elements? Camera matrix is at the end of the day matrix from $\mathbf{R}^{3x4}$. Scaling by nonzero constant do not change its properties as a projective element. Therefore using this fact we can encode source to detector distance into the matrix. On the other hand we don't need this information in order to make CT projection or reconstruction anyway. Camera matrix does not tell us, what is the size of the detector and this information must be provided to the reconstruction software by other means. For example to do a projection using KCT framework, we need to specify&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;    --projection-sizex UINT Needs: --projection-sizey
                                X dimension of detector in pixel count, defaults to 616.
    --projection-sizey UINT Needs: --projection-sizex
                                Y dimension of detector in pixel count, defaults to 480.
&lt;/code&gt;&lt;/pre&gt;


&lt;h4&gt;Creating camera matrices for particular setup&lt;/h4&gt;
&lt;p&gt;The &lt;a href="https://en.wikipedia.org/wiki/Camera_matrix"&gt;Camera matrix&lt;/a&gt; is relatively well described on Wikipedia. So let's construct set of camera matrices to be used in the KCT framework. To store them, we use &lt;a href="https://kulvait.github.io/KCT_doc/den-format.html"&gt;DEN file&lt;/a&gt; format of the size float64 with $(dimx, dimy, dimz)=(4,3,n)$, where n is number of the configurations in given FDCT trajectory.&lt;/p&gt;
&lt;p&gt;Let's have the following setup. Zero of the world coordinates coincide with the volume center. Source and detector rotate along $x_3$ axis and $\chi_2$ is parallel with $x_3$. Principal ray at every position of the trajectory hits the detector. The  distance  from  the source  to  theisocenter  is $I = 749mm$ and  the  distance  from  source to the detector is $A=1198mm$. Trajectory consist of $360$ views and in the view $\omega$ the normal to the detector pointing towards the source forms the polar angle with respect to $x_1$ and $x_2$ axes so that $n_\omega = (cos(\omega), sin(\omega))$. Finally let's have $PX\times PY$ = $0.616mmx0.616mm$ pixels and $M\times N = 616x480$ grid.&lt;/p&gt;
&lt;p&gt;From this information we construct camera matrix for given projection setup. First we perform a transformation to the local coordinate system related to the given view $\omega$ that will be more convenient to work with. In the terminology of projection matrices, we understand the point in 3D as a point of projective space of dimension 3, which can be represented by the vector $(x_1, x_2, x_3, 1)$. We use this just as a vehicle to encode source position into the projection matrix not to exploit some topological properties of $\mathbb{R}^4$, but let's respect this usual way how to construct projection matrices. So that linear transformations in this kind of space will be transformations between $\mathbb{R}^4$ encoded by means of matrices from $\mathbb{R}^{4\times4}$.&lt;/p&gt;
&lt;p&gt;First we just perform a rotation of the axes $x_1,x_2,x_3$ so that $x_1',x_2',x_3'$ will again form Cartesian coordinate system but rotated towards our setup. Let's identify positive direction of $x_3'$ with positive direction of $\chi^2$ by $x_3'=-x_3$. We rotate remaining two axes in the way that $x_2'$ unit vector will be the normal vector $n_\omega$ and $x_1'$ will be colinear with $\chi^1$ on the detector. So we use the following projective element 
$$
\mathbf{X}_1 =
\begin{pmatrix} 
-\sin{\omega}&amp;amp; \cos{\omega} &amp;amp;0 &amp;amp;0 \\
\cos{\omega}&amp;amp; \sin{\omega}&amp;amp;0 &amp;amp;0 \\ 
0&amp;amp;0&amp;amp;-1&amp;amp;0 \\
0&amp;amp;0&amp;amp;0&amp;amp;1 
\end{pmatrix}.
$$&lt;/p&gt;
&lt;p&gt;Now the $\mathbf{X}_1$ took us into a new coordinate system, let's live in it and shift its origin to $S'$. First let's relize that coordinates of $S' = (0, \sqrt{s_1^2+s_2^2}, -s_3, 1)$. Now we can do a shift by means of the next projective element
$$
\mathbf{X}_2 = \begin{pmatrix} 
1&amp;amp;0&amp;amp;0&amp;amp;0\\
0&amp;amp;1&amp;amp;0&amp;amp;-\sqrt{s_1^2+s_2^2}\\
0&amp;amp;0&amp;amp;1&amp;amp;s_3\\
0&amp;amp;0&amp;amp;0&amp;amp;1
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;So we constructed projective element such that
$$
\begin{pmatrix} x_1'' \\ x_2''\\x_3''\\1 \end{pmatrix} = \mathbf{X}_2 \mathbf{X}_1 \begin{pmatrix} x_1\\x_2\\x_3\\1 \end{pmatrix}.
$$&lt;/p&gt;
&lt;p&gt;Now let's construct the projective element from 3D transformed space to the detector. But simpler detector with the same orientation as our flat panel but with the zero positioned at principal point and moreover detector such, that unit vector $x_3''$ from principal point projects to 1 in $\chi^2$ direction and unit vector $x_2''$ project to 1 in $\chi_1$ direction. This detector must have focal length $A$ so that we can construct the following projective element
$$
\mathbf{E} =
\begin{pmatrix}
1&amp;amp;0&amp;amp;0&amp;amp;0\\
0&amp;amp;0&amp;amp;1&amp;amp;0\\
0&amp;amp;-\frac{1}{A}&amp;amp;0&amp;amp;0
\end{pmatrix}
$$
Notice sign to correct for the fact that $x_2''$ points from detector to source and not vice versa. We know, that the unit vectors project to the distance $1/PX$ or $1/PY$ respectivelly. Let's add another projective element to correct for the pixel sizes
$$
\mathbf{A}_1 =
\begin{pmatrix}
\frac{1}{PX}&amp;amp;0&amp;amp;0\\
0&amp;amp;\frac{1}{PY}&amp;amp;0\\
0&amp;amp;0&amp;amp;1
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;Here is obvious that the operation of cutting pixels into $kxk$ subpixels can be realized by matrix
$$
\begin{pmatrix}
k&amp;amp;0&amp;amp;0\\
0&amp;amp;k&amp;amp;0\\
0&amp;amp;0&amp;amp;1
\end{pmatrix}
$$
and splitting is realized by inverse operation
$$
\begin{pmatrix}
\frac{1}{k}&amp;amp;0&amp;amp;0\\
0&amp;amp;\frac{1}{k}&amp;amp;0\\
0&amp;amp;0&amp;amp;1
\end{pmatrix}.
$$&lt;/p&gt;
&lt;p&gt;To shift the $\chi^{(0,0)}$ to its intended position let's do this
\begin{equation}
\mathbf{A}_2 =
\begin{pmatrix}
1&amp;amp;0&amp;amp;\frac{N-1}{2}\\
0&amp;amp;1&amp;amp;\frac{M-1}{2}\\
0&amp;amp;0&amp;amp;1
\end{pmatrix}
\end{equation}&lt;/p&gt;
&lt;p&gt;In the KCT we use the convention that integer projection coordinates denote center of given pixel.
Therefore zero is achieved at the center of corner pixel.&lt;/p&gt;
&lt;p&gt;Finally we obtain projection matrix that for given position in the volume provides the position on the projector
$$
\mathbf{P} = \mathbf{A}_2 \mathbf{A}_1 \mathbf{E} \mathbf{X}_2 \mathbf{X}_1.
$$&lt;/p&gt;
&lt;h3&gt;Python implementation&lt;/h3&gt;
&lt;p&gt;We have yet mastered the theory so let's produce the set of camera matrices for given trajectory.&lt;/p&gt;&lt;/div&gt;</description><category>using_kct_blog</category><guid>https://kulvait.github.io/KCT_doc/posts/working-with-kct-cbct-2-projective-geometry-and-camera-matrices-to-describe-ct-geometry.html</guid><pubDate>Tue, 14 Sep 2021 10:05:50 GMT</pubDate></item><item><title>Working with KCT CBCT 1 Converting DICOM volume to DEN volume</title><link>https://kulvait.github.io/KCT_doc/posts/working-with-kct-cbct-1-converting-dicom-volume-to-den-volume-using-dicom-data-from-public-repository.html</link><dc:creator>Vojtěch Kulvait</dc:creator><description>&lt;div&gt;&lt;p&gt;In this series of blog posts, I will describe how to work with the KCT framework from the first steps of importing data to the more advanced topics as a running reconstruction. &lt;/p&gt;
&lt;p&gt;In the post today, I explain how to import files in DICOM into the DEN format that is used within the framework. I use the data from the public repository.&lt;/p&gt;
&lt;h3&gt;Example dataset&lt;/h3&gt;
&lt;p&gt;I have choosen a publicly available dataset from &lt;a href="https://public.cancerimagingarchive.net/"&gt;The Cancer Imaging Archive&lt;/a&gt; containing a brain CT scan, ID TCGA-19-1787. To download this dataset I followed the procedure described on &lt;a href="https://wiki.cancerimagingarchive.net/display/NBIA/Downloading+TCIA+Images"&gt;The Cancer Imaging Archive page&lt;/a&gt;. It is needed to instal their application NBIA Data Retriever and provide it with the information in the &lt;code&gt;manifest-1631446347856.tcia&lt;/code&gt; file, which must contain the following&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;downloadServerUrl&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;https&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;public&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cancerimagingarchive&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;nbia&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;servlet&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;DownloadServlet&lt;/span&gt;
&lt;span class="n"&gt;includeAnnotation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;true&lt;/span&gt;
&lt;span class="n"&gt;noOfrRetry&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;databasketId&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;manifest&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1631446347856.&lt;/span&gt;&lt;span class="n"&gt;tcia&lt;/span&gt;
&lt;span class="n"&gt;manifestVersion&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;3.0&lt;/span&gt;
&lt;span class="n"&gt;ListOfSeriesToDownload&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;
&lt;span class="mf"&gt;1.3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;6.1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;4.1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;14519.5&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;2.1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;5826.4001&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;312669389023517091391958251391&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;


&lt;p&gt;Example dataset is published under the terms of &lt;a href="http://creativecommons.org/licenses/by/3.0/"&gt;Creative Commons Attribution 3.0 Unported License&lt;/a&gt; and the &lt;a href="https://kulvait.github.io/KCT_doc/license-tcga-gbm.html"&gt;following terms&lt;/a&gt;. This licencing apply to any user even the user of the derived data, which I publish here in scope of this demonstration in &lt;a href="https://github.com/kulvait/KCT_den_file_opener/releases/download/v1.1.1/ExampleVolumeKCT_TCGA-19-1787.tar.xf"&gt;Example Volume TCGA-19-1787&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When we unpack the data of example volume, we see that dicom files with the suffix dcm are in the directory &lt;code&gt;TCGA-19-1787/04-20-2002-NA-NR CT HEAD W CE-97133/2.000000-Head Vol.  1.5  H40s ST-51391&lt;/code&gt;. For simplicity I rename this directory just to DICOM and remove parent subdirectories. 
From the DICOM headers we can see that it is a scan on SIEMENS Sensation Cardiac 64 CT machine. It contains $124$ slices with the thickness of $1.5$mm of the dimension $512 \times 512$, the voxel sizes are ($0.64453125$mm, $0.64453125$mm, $1.5$mm).&lt;/p&gt;
&lt;h3&gt;Conversion of DICOM series to DEN format&lt;/h3&gt;
&lt;p&gt;For the purpose of this example, we have to transform the DICOM dataset into the &lt;a href="https://kulvait.github.io/KCT_doc/den-format.html"&gt;DEN format&lt;/a&gt;, which is used by KCT framework. We do it using &lt;a href="https://github.com/kulvait/KCT_denpy"&gt;KCT_denpy package&lt;/a&gt;. This package allow us to convert between the representations of the volume data as numpy.ndarray, DEN file or DICOM series. Internally it uses the package pydicom to read DICOM data.&lt;/p&gt;
&lt;p&gt;For the conversion, I have created a simple script &lt;code&gt;[DICOMTODEN.py](https://github.com/kulvait/KCT_scripts/blob/master/DICOMTODEN.py)&lt;/code&gt;. The command to convert the data to the DEN format will then be&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;DICOMTODEN.py --force --dicom-file-suffix &lt;span class="s2"&gt;"dcm"&lt;/span&gt; DICOM DEN_HU
&lt;/code&gt;&lt;/pre&gt;


&lt;p&gt;After you run this command, the new directory &lt;code&gt;DEN_HU&lt;/code&gt; will be created, which contains file &lt;code&gt;Series_00.den&lt;/code&gt;. This is a converted DICOM file into the DEN format. To vizualize the volume can be used &lt;a href="https://github.com/kulvait/KCT_den_file_opener/releases/download/v1.1.1/KCT_Den_File_Opener-1.1.1.jar"&gt;KCT Den file opener&lt;/a&gt;, a plugin of &lt;a href="https://imagej.nih.gov/ij/"&gt;ImageJ&lt;/a&gt; viewer that works also with &lt;a href="https://imagej.net/software/fiji/"&gt;Fiji&lt;/a&gt;. It is sufficient to put a file KCT_Den_File_Opener-1.1.1.jar into the .imagej/plugins configuration directory of ImageJ. Then simpy select &lt;code&gt;File-&amp;gt;Open DEN ..&lt;/code&gt; and navigate to &lt;code&gt;Series_00.den&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can notice that the values are integers starting from $-1024$ in the areas of the air up to values greater than $1000$ in the dense bone areas. These are in (Hounsfield units)[https://en.wikipedia.org/wiki/Hounsfield_scale], which are good for the physicans to compare tissue contrasts in a convenient scale, but they do not represent raw attenuation values. To do a projection of the data using KCT or reconstruction of these projections, we need raw attenuation values.&lt;/p&gt;
&lt;p&gt;Conversion between Hounsfield units and raw attenuation values is possible using (KCT dentk toolkit)[https://github.com/kulvait/KCT_dentk]. Install the tool &lt;code&gt;dentk-fromhu&lt;/code&gt; to your path and then the conversion can be done either by calling&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;dentk-fromhu Series_00.den Series_00.raw
&lt;/code&gt;&lt;/pre&gt;


&lt;p&gt;or using the script &lt;code&gt;DICOMTODEN.py&lt;/code&gt; to internally call &lt;code&gt;dentk-fromhu&lt;/code&gt; and to produce raw attenuations&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;DICOMTODEN.py --force --dicom-file-suffix &lt;span class="s2"&gt;"dcm"&lt;/span&gt; --convert-hu-to-raw --base2 DICOM DEN_RAW
&lt;/code&gt;&lt;/pre&gt;


&lt;p&gt;There are two caveats. First for the conversion is important the attenuation value of the water, which in Hounsfield units is exactly $0$. By default the conversion will be performed in the same way as with the setting &lt;code&gt;--water-value 0.027&lt;/code&gt;. If you know the exact attenuation value of the water for given scanner, feel free to change it.&lt;/p&gt;
&lt;p&gt;Second there is a problem that in &lt;a href="https://en.wikipedia.org/wiki/Hounsfield_scale"&gt;wiki article about Hounsfield units&lt;/a&gt; as well as in virtually every CT textbook, you can find that the minimum Hounsfield unit is 1000. DICOM data from SIEMENS scanners tend to have this minimum value $-1024$. It is due to the better data alignment with uint16 or uint32 representation of offsetted Hounsfield units. Standard conversion formula would however produce negative attenuation values. To correct for this undesired behavior we have to add &lt;code&gt;--base2&lt;/code&gt; as a parameter either to &lt;code&gt;DICOMTODEN.py&lt;/code&gt; or &lt;code&gt;dentk-fromhu&lt;/code&gt; program.&lt;/p&gt;
&lt;h3&gt;Vizualizing DEN volume of raw attenuation values derived from DICOM series&lt;/h3&gt;
&lt;p&gt;When you did everything correct, in the directory &lt;code&gt;DEN_RAW&lt;/code&gt; is the file &lt;code&gt;Series_00.den&lt;/code&gt;, which represent raw attenuation values derived from given DICOM series. You can also download &lt;a href="https://github.com/kulvait/KCT_den_file_opener/releases/download/v1.1.1/ExampleVolumeKCT_TCGA-19-1787.tar.xf"&gt;Example Volume TCGA-19-1787&lt;/a&gt;, which contain also the converted DEN volume.&lt;/p&gt;
&lt;p&gt;When vizualizing in ImageJ, you can select an area of the soft tissue and press ALT+CTRL+C. Then you can adjust the contrast. &lt;/p&gt;
&lt;p&gt;Investigating the volume in more detail from the perspective of data alignment it is apparent that the convention described on the picture &lt;a href="https://www.slicer.org/wiki/File:Coordinate_sytems.png"&gt;CT coordinates, image from the project slicer&lt;/a&gt; is observed. So that z axis is the axis of the rotation. Y axis goes from the top (above scanned subject) to bottom (under scanned object). Note, that ImageJ places the (0,0) top left and the positive direction of the Y axis is also top to bottom so that the axial image is vizualized in a natural orientation.  &lt;/p&gt;
&lt;h3&gt;Working with KCT CBCT 2&lt;/h3&gt;
&lt;p&gt;In the next post, I will explain what are the conventions for the projection geometry and how to describe the geometric setting of the flat detector CT. We define an example setup of a virtual flat detector CT machine when scannin the volume created in this post. We then use KCT framework to project the volume and create projections.&lt;/p&gt;&lt;/div&gt;</description><category>using_kct_blog</category><guid>https://kulvait.github.io/KCT_doc/posts/working-with-kct-cbct-1-converting-dicom-volume-to-den-volume-using-dicom-data-from-public-repository.html</guid><pubDate>Mon, 13 Sep 2021 10:44:40 GMT</pubDate></item><item><title>KCT framework</title><link>https://kulvait.github.io/KCT_doc/posts/kct-framework.html</link><dc:creator>Vojtěch Kulvait</dc:creator><description>&lt;div&gt;&lt;p&gt;KCT framework is a set of sotware tools to process computer tomography data. It was founded by Vojtěch Kulvait to support his PostDoc research at University of Magdeburg 2018-2021. Work is focused on processing, manipulating and reconstructing the data from the C-Arm CT systems with a flat panel detector, FDCT. It consists of multiple packages described below.&lt;/p&gt;
&lt;p&gt;These tools are tested and the compatibility will be maintained towards Debian 11 bullseye with AMD64 CPU. After the compilation, command line programs are built, which use command line parser (CLI11)[https://github.com/CLIUtils/CLI11] to specify inputs, outputs and parameters. BASH scripting is a common practice to put these programs into the CT data processing functional pipelines. &lt;/p&gt;
&lt;h3&gt;&lt;a href="https://github.com/kulvait/KCT_cbct"&gt;KCT cbct&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Contains C++ and OpenCL implementation of various methods for algebraic CT reconstruction.&lt;/p&gt;
&lt;h3&gt;&lt;a href="https://github.com/kulvait/KCT_dentk"&gt;KCT dentk&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;It contains tools written in C++ to process files in the &lt;a href="https://kulvait.github.io/KCT_doc/posts/DEN-format"&gt;DEN format&lt;/a&gt; to store 3D volume data. Format is derived and compatible with the format reffered as Dennerlein or DEN format.&lt;/p&gt;
&lt;h3&gt;&lt;a href="https://github.com/kulvait/KCT_denpy"&gt;KCT denpy&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Python package to manipulate filues in DEN format. It uses pydicom package to read DICOM data. Files in formats is possible to convert to numpy.ndarray. By this mechanism is possible to convert series of DICOM files into the DEN files that are used within the framework. &lt;/p&gt;
&lt;h3&gt;&lt;a href="https://github.com/kulvait/KCT_ctiol"&gt;KCT ctiol&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;C++ library with input output routines for asynchronous thread safe reading/writing CT data. This library is typically a dependency/submodule of other C++ tools in KCT.&lt;/p&gt;
&lt;h3&gt;&lt;a href="https://github.com/kulvait/KCT_ctmal"&gt;KCT ctmal&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;C++ library with mathematic/algebraic algorithms for supporting CT data manipulation. This library is typically a dependency/submodule of other C++ tools in KCT.&lt;/p&gt;&lt;/div&gt;</description><guid>https://kulvait.github.io/KCT_doc/posts/kct-framework.html</guid><pubDate>Mon, 13 Sep 2021 10:04:57 GMT</pubDate></item></channel></rss>